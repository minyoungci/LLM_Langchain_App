
# LangChain framework 소개

대규모 언어 모델(LLM)을 위한 효과적인 프롬프트를 작성하는 데는 기술이 필요하지만 LLM 사용법은 대체로 간단합니다. 반면 언어 모델을 사용한 프로그래밍은 어려울 수 있습니다. 그럴 때 [랭체인(LangChain)](https://www.langchain.com/)을 사용하면 됩니다.

랭체인은 언어 모델이 데이터 소스에 연결하고 환경과 상호작용할 수 있게 해준다. 랭체인 주요 요소는 모듈식 추상화 및 추상화 구현의 모음으로 구성돼 있다. 랭체인 기성형(off-the-shelf) 체인은 특정 상위 수준의 작업을 수행하기 위한 구성 요소의 구조화된 어셈블리다. 구성요소를 사용해 기존 체인을 맞춤설정하고 새 체인을 만들 수 있다.   
  
언어 모델에는 LLM과 채팅 모델, 두 종류가 있다. LLM은 문자열을 입력으로 받고 문자열을 반환한다. 채팅 모델은 메시지 목록을 입력으로 받고 채팅 메시지를 반환한다. 채팅 메시지에는 내용과 역할, 두 가지 구성요소가 포함된다. 역할은 사람, AI, 시스템, 함수 호출 또는 일반 입력 등 내용이 어디서 오는지를 지정한다.  
  
일반적으로 LLM은 입력에 프롬프트 템플릿을 사용한다. 프롬프트 템플릿을 사용해 LLM 또는 채팅 모델이 취할 역할, 예를 들어 “영어를 프랑스어로 번역하는 유용한 비서” 등을 지정할 수 있다. 또한 프롬프트 템플릿을 이용하면 번역할 구문 목록과 같은 다양한 내용 인스턴스에 이 템플릿을 적용할 수 있다.   

*LangChain이 작동하는 방식인 6개의 모듈*
![[Pasted image 20230920205315.png]]

1. [모델 I/O](https://python.langchain.com/docs/modules/model_io/) : 언어 모델과의 인터페이스 
2. [데이터 연결](https://python.langchain.com/docs/modules/data_connection/) : 애플리케이션별 데이터와의 인터페이스 
3. [체인](https://python.langchain.com/docs/modules/chains/) : 호출 시퀀스 구축 
4. [에이전트](https://python.langchain.com/docs/modules/agents/) : 상위 지시문이 주어지면 체인이 사용할 툴을 선택할 수 있도록 함 
5. [메모리](https://python.langchain.com/docs/modules/memory/) : 체인 실행 간에 애플리케이션 상태 유지 
6. [콜백](https://python.langchain.com/docs/modules/callbacks/) : 체인의 중간 단계를 기록 및 스트리밍
# LangChain 모듈

Model I/O는 프롬프트를 관리하고 공통 인터페이스를 통해 언어 모델을 호출하고 모델 출력에서 정보를 추출할 수 있게 해준다. 

![[Pasted image 20230920205045.png]]

데이터 연결은 데이터를 로드, 변형, 저장 및 쿼리하기 위한 빌딩 블록을 제공합니다. 

![[Pasted image 20230920205104.png]]

복잡한 애플리케이션은 LLM을 상호, 또는 다른 구성요소와 체인으로 연결해야 한다. 랭체인은 이러한 “체인으로 연결된” 애플리케이션을 위한 체인 인터페이스를 제공한다. 대화형 시스템은 어느 정도 기간의 과거 메시지에 직접 액세스할 수 있어야 한다. 랭체인에서는 이 기능을 **메모리**라고 한다.

![[Pasted image 20230920205200.png]]

## Agents 

LangChain Agents 문서 : [https://python.langchain.com/docs/modules/agents/]

LLM은 특정한 날짜를 기준 삼아 훈련을 받습니다. 
예를 들어 사용자가 석유 시가에 대해서 알고 싶거나 최신 시사 정보, 특정 국가의 날씨 등과 같은 질문을 하면 LLM은 대답할 수 없습니다. 인터넷 연결 없이는 최신 정보를 확보할 수 없는 것이죠. 
그러므로 최신 정보는 다루지 못합니다.

특정 데이터베이스나 외부 소스에 대한 접근 권한을 얻거나 간단한 API를 호출을 하고 싶다고 가정해봅시다.
바로 이때 필요한 것이 **Agent** 입니다. **Agent** 는 봇이라고 생각하면 편합니다. 
사용자를 대신해 작업을 수행하고 LLM들과 소통할 수 있습니다. 

<img width="1304" alt="스크린샷 2023-09-20 16 11 00" src="https://github.com/minyoungci/LLM_Langchain_app/assets/80457917/8d11c4d8-ba7b-4b32-84c4-6bede789af60">
작업들을 서로 연결하고, 출력 내용을 LLM에 전달한 후에 출력 내용을 다시 가져온 후에 다른 작업도 수행하므로 작업을 하나씩 연결해서 복잡한 애플리케이션을 구축할 수 있습니다. 

LLM에게 이 세상의 모든 데이터에 접근할 수 있는 초능력을 줄 수 있답니다. 

이제 Agent 툴을 사용합니다. 툴은 LangChain에서 사용하는 용어입니다. 그렇다면 대체 툴이란 것은 무엇일까요? 
**간단히 설명하면, 툴은 위의 그림에서 화살표랑 같습니다.**
툴은 LangChain 프레임워크와 third party, 즉 외부 서비스를 연결합니다. 
하지만 Agent는 단순한 API 호출, 외부 서비스와의 소통을 뛰어넘는 강력한 성능을 지녔습니다. 
Agent는 실제로 어떤 기능을 담당하냐면 LLM을 사용하여 다음과 같은 작업을 수행합니다. 

<img width="1364" alt="스크린샷 2023-09-20 15 47 17" src="https://github.com/minyoungci/LLM_Langchain_app/assets/80457917/066d30e1-c60a-4a57-96e0-9e55d2dfa8c6">
수행해야 하는 테스크가 있고 이를 수행할 Agent를 정의하는 경우 Agent에게 '도움이 필요해'라고 말하면 Agent는 요청하는 사용자가 원하는 것을 수행하기 위해 뭘 해야하는지 스스로 질문합니다. 

그런 다음 수행 단계 목록을 직접 정렬합니다. Agent는 외부 API 호출, 데이터 베이스 엑세스, 하위 작업 수행 등의 단계를 처리한 다음에 응답을 반환하는 능력을 갖게 됩니다. 

### Agent 작동 원리

기본적으로 Agent의 엔진은 LLM입니다. 그래서 Agent에게 작업을 맡기면 에이전트는 가장 먼저 큰 과제를 달성하고 완료하기 위해 어떤 하위 작업을 수행해야 할지 계산합니다. 
이러한 질문에 답하고 하위 작업을 세분화하는 작업은 LLM이 충분히 소화할 수 있습니다. 

프롬프트 엔지니어링(Prompt Engineering)에 익숙하지 않아도 충분히 할 수 있습니다. 
Agent는 수행해야 하는 하위 작업들을 나열할 뿐만 아니라 데이터베이스를 외부 호출하거나 온라인 검색도 할 수 있습니다. Agent는 이러한 하위 작업을 수행하는 능력을 갖고 있습니다. 

그래서 Agent가 이러한 하위 작업을 완료하면 원하는 답변을 돌려줄 수 있는 것이죠. 
결국 이 기능은 Reasoning과 Acting, 즉 추론과 행동을 결합했다고 이해하면 됩니다. 
이것 또한 마찬가지로 프롬프트 엔지니어링 테크닉이라고 합니다. 

코드는 공식 문서에서 확인합시다. 툴을 사용할 수  있는 다양한 방식이 소개되어 있습니다.

Tool code snipet 
``` python
from langchain.agents import load_tools  
tool_names = [...]  
tools = load_tools(tool_names)
```

